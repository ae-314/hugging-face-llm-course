# -*- coding: utf-8 -*-
"""token_classification_wnut_model_demo.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/17G5_SWHSimoFIm-Q9zt4CyoOhMg1Rq41
"""

# aaron e
# ae-314

# Demo of my finely tuned token classification model for Named Entity Recognition
# Trained on local db: manu/wnut_17 vs. tutorial dataset wnut_17 because of datasets version 4.0 changes
# Changed hyperparameters: learning rate, warmup_ratio. LR changed from 2 e-5 to 1 e-9 and added warmup_ratio = 0.1
# This demo notebook includes a few examples of the model being used for NER
# NOTE: install transformers directly from source to avoid import issues because of version changes

#!pip install -U transformers
! pip install git+https://github.com/huggingface/transformers.git

"""## Local Inference on GPU
Model page: https://huggingface.co/ae-314/token_classification_wnut_model

‚ö†Ô∏è If the generated code snippets do not work, please open an issue on either the [model repo](https://huggingface.co/ae-314/token_classification_wnut_model)
			and/or on [huggingface.js](https://github.com/huggingface/huggingface.js/blob/main/packages/tasks/src/model-libraries-snippets.ts) üôè
"""

# Use a pipeline as a high-level helper
from transformers import pipeline

pipe = pipeline("token-classification", model="ae-314/token_classification_wnut_model")

example_1 = "Agnes Arber was a botanist and the author of 'Herbals:Their Origin and Evolution', as well as being a Fellow of the Royal Society in London."

pipe(example_1)

# Load model directly
from transformers import AutoTokenizer, AutoModelForTokenClassification

tokenizer = AutoTokenizer.from_pretrained("ae-314/token_classification_wnut_model")
inputs = tokenizer(example_1, return_tensors="pt") # give the model inputs
model = AutoModelForTokenClassification.from_pretrained("ae-314/token_classification_wnut_model")

import torch

with torch.no_grad():
  logits = model(**inputs).logits

# get the class predictions in human-readable labels

predictions = torch.argmax(logits, dim=2)
predicted_token_class = [model.config.id2label[t.item()] for t in predictions[0]]
predicted_token_class

example_2 = "Jules Richard Petri invented the Petri dish during his time at Berlin University."

pipe(example_2)

example_3 = "The World Wildlife Fund (WWF) was founded in 1961, is focused on conservation, and is based in Switzerland."

pipe(example_3)

example_4 = "The Golden State Warriors are an American professional basketball team based in San Francisco."

pipe(example_4)