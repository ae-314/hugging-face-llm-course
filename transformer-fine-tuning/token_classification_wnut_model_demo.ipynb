{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kaggle": {
      "accelerator": "gpu"
    },
    "language_info": {
      "name": "python"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
},
    
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# aaron e\n",
        "# ae-314\n",
        "\n",
        "# Demo of my finely tuned token classification model for Named Entity Recognition\n",
        "# Trained on local db: manu/wnut_17 vs. tutorial dataset wnut_17 because of datasets version 4.0 changes\n",
        "# Changed hyperparameters: learning rate, warmup_ratio. LR changed from 2 e-5 to 1 e-9 and added warmup_ratio = 0.1\n",
        "# This demo notebook includes a few examples of the model being used for NER\n",
        "# NOTE: install transformers directly from source to avoid import issues because of version changes\n",
        "\n",
        "#!pip install -U transformers\n",
        "! pip install git+https://github.com/huggingface/transformers.git"
      ],
      "metadata": {
        "id": "RF7KC5k9mown",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d4ec8b3a-0ab5-48a7-ee6f-bf394dee9eca"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting git+https://github.com/huggingface/transformers.git\n",
            "  Cloning https://github.com/huggingface/transformers.git to /tmp/pip-req-build-bxr5fh5_\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/huggingface/transformers.git /tmp/pip-req-build-bxr5fh5_\n",
            "  Resolved https://github.com/huggingface/transformers.git to commit 307c5238546ba1675daabc46050c63ffde25f8e6\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from transformers==5.0.0.dev0) (3.20.0)\n",
            "Requirement already satisfied: huggingface-hub==1.0.0.rc6 in /usr/local/lib/python3.12/dist-packages (from transformers==5.0.0.dev0) (1.0.0rc6)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.12/dist-packages (from transformers==5.0.0.dev0) (2.0.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from transformers==5.0.0.dev0) (25.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.12/dist-packages (from transformers==5.0.0.dev0) (6.0.3)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.12/dist-packages (from transformers==5.0.0.dev0) (2024.11.6)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from transformers==5.0.0.dev0) (2.32.4)\n",
            "Requirement already satisfied: tokenizers<=0.23.0,>=0.22.0 in /usr/local/lib/python3.12/dist-packages (from transformers==5.0.0.dev0) (0.22.1)\n",
            "Requirement already satisfied: typer-slim in /usr/local/lib/python3.12/dist-packages (from transformers==5.0.0.dev0) (0.19.2)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.12/dist-packages (from transformers==5.0.0.dev0) (0.6.2)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.12/dist-packages (from transformers==5.0.0.dev0) (4.67.1)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub==1.0.0.rc6->transformers==5.0.0.dev0) (2025.3.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub==1.0.0.rc6->transformers==5.0.0.dev0) (0.28.1)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub==1.0.0.rc6->transformers==5.0.0.dev0) (4.15.0)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub==1.0.0.rc6->transformers==5.0.0.dev0) (1.1.10)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->transformers==5.0.0.dev0) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests->transformers==5.0.0.dev0) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests->transformers==5.0.0.dev0) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests->transformers==5.0.0.dev0) (2025.10.5)\n",
            "Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.12/dist-packages (from typer-slim->transformers==5.0.0.dev0) (8.3.0)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->huggingface-hub==1.0.0.rc6->transformers==5.0.0.dev0) (4.11.0)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->huggingface-hub==1.0.0.rc6->transformers==5.0.0.dev0) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->huggingface-hub==1.0.0.rc6->transformers==5.0.0.dev0) (0.16.0)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.12/dist-packages (from anyio->httpx<1,>=0.23.0->huggingface-hub==1.0.0.rc6->transformers==5.0.0.dev0) (1.3.1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Local Inference on GPU\n",
        "Model page: https://huggingface.co/ae-314/token_classification_wnut_model\n",
        "\n",
        "‚ö†Ô∏è If the generated code snippets do not work, please open an issue on either the [model repo](https://huggingface.co/ae-314/token_classification_wnut_model)\n",
        "\t\t\tand/or on [huggingface.js](https://github.com/huggingface/huggingface.js/blob/main/packages/tasks/src/model-libraries-snippets.ts) üôè"
      ],
      "metadata": {
        "id": "8wFow7kPmowp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Use a pipeline as a high-level helper\n",
        "from transformers import pipeline\n",
        "\n",
        "pipe = pipeline(\"token-classification\", model=\"ae-314/token_classification_wnut_model\")"
      ],
      "metadata": {
        "id": "4hXe2FvJmowq",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 335,
          "referenced_widgets": [
            "e8346dc800734d06b69c0f6758a9ec95",
            "f99b7b68c9cc4d12a19f92aceb94c05d",
            "ba09e7e61b6f421bbc3fd9797d01e538",
            "0faf796165af41b4832c6c5bf6270216",
            "f4ef7e5d5f84415ea1511e70ddbc3631",
            "b68d2de2baa849e0a9acadeff19c0b90",
            "bc224a6d16624b63b02c9fbc22bcb4ca",
            "8f9f1addeccd441aa48ece9d47b763b5",
            "2e8471652fe14eada3aaa55b0b21725f",
            "42981e0b5bca43018d41064b8f8d2ecd",
            "d667cb2bb2cd4ad4b52b142f8e812a18",
            "8aba707e60b64627843b9fa25832be8a",
            "fc577ce85e884dc39913762927919ccc",
            "5bbdf4578620460e8751ea8108dc01ac",
            "2ab15538372e49b7b79b00b30870cdd6",
            "fc2b49b37ce242698e02a0c7da1cff68",
            "a944cf929dbe40c2885e5b5e74fa2aee",
            "873930837f8944e4a9751b0fc4c1f8e3",
            "7f505de3cf1f4b73acf3495910d8d2fd",
            "9295200f268c4e669dbd76e380f33363",
            "615afea148b6447b8f8fe0140819aee5",
            "a1bb2849e2fb42aebc6b3e98f980faa8",
            "ee3fedb4fb6049fe92f17cb30f8e024d",
            "fe7b3169428740b6b9bbd79ca7565c1b",
            "c9c2adfaff134051a3ecb306e47ce690",
            "25c79800734d4b98b8ac70194c2934e2",
            "4029c852a8784c1ab74dbd44d5b21915",
            "d417aa90eebf4b49afa5e1a0b6ace463",
            "dc83bc2ba6e34f6db192325dafadb953",
            "8d044f8b984948819ec8e9cc03027bdb",
            "56b08178271e42159cec3ab3742f4ee0",
            "7cb22be7b5cd45ad94bc9110e57ce823",
            "d54c5d5f2971415c8bd67c4e4404cf93",
            "3e2ff53e00864c0dbc47f0932cc509d3",
            "d9f47ce9792f47ad8d4b22d6954c89d6",
            "08dffdfebf32461a8995c9f6d1182588",
            "1fc0485d7d624c5a82907a961cf28e9d",
            "81ad633f28ab4845b8a430fec18ee977",
            "534764e266e740d9b1c53224b6b59ef5",
            "c6ff0139c8db452d9066a511e42b22be",
            "7f3514d74b0b430f97172835352fba45",
            "27293c55c72843f99fb8b400ff574f63",
            "97b6731c42464d51b30e983d3c65304e",
            "37e22ef9d6ba455089e4ba2d701b850a",
            "a5e40a461ef64495b5275b3bfdc4b044",
            "a25673e2879948c3a6e7bc6fa4aa92ce",
            "c06834822bab4d4c9fad160c2de2be7f",
            "fcfc924634894da6b11112e2be2f2772",
            "47bc32d9c7304c96ad8df81401517e1b",
            "42ebeebda4f343b5a381a7df25f188dd",
            "62bc5c9449d74274a0a5e894332fcd8a",
            "e932ee4e988742ea96bca31f9fbcff93",
            "789c344d17c54e5ea3de84f767f76b99",
            "59517592e3884811b607e0612a68e5fe",
            "a765083c566b41ab996f27202f869acf",
            "fdcd3558ff484b3182b31233d46fdb8d",
            "01cb950cc9af463b999348a65c15b5fc",
            "704e1e3327754beeaaa3b22c84121ae8",
            "a70b1df436d344028c22c9e33eac3a79",
            "c9a98c968f914ccc9980a76167b213dc",
            "726bde4e537f48cba075497b7f046611",
            "74dfeeba458b4a2395994a56ddec79d7",
            "1276f939697e44a3bb0e37b0ebdb9f7f",
            "3ddc2819ad3c4f6eadd16b2b194c624b",
            "9eb796c910764f42a516ceee41df8fc7",
            "2cc4c71a6dfb40ed84a1bfa35d027809"
          ]
        },
        "outputId": "fde4cfcc-78a8-4742-f0d7-34e0bd260763"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config.json: 0.00B [00:00, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "e8346dc800734d06b69c0f6758a9ec95"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/266M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "8aba707e60b64627843b9fa25832be8a"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer_config.json: 0.00B [00:00, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "ee3fedb4fb6049fe92f17cb30f8e024d"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "vocab.txt: 0.00B [00:00, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "3e2ff53e00864c0dbc47f0932cc509d3"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer.json: 0.00B [00:00, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "a5e40a461ef64495b5275b3bfdc4b044"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "special_tokens_map.json:   0%|          | 0.00/695 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "fdcd3558ff484b3182b31233d46fdb8d"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "example_1 = \"Agnes Arber was a botanist and the author of 'Herbals:Their Origin and Evolution', as well as being a Fellow of the Royal Society in London.\""
      ],
      "metadata": {
        "id": "qZ4ek75Urv7e"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pipe(example_1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GhR-d2Drs3we",
        "outputId": "559e4348-a5ea-4c40-de84-4d90dc3f1a12"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'entity': 'B-person',\n",
              "  'score': np.float32(0.9910617),\n",
              "  'index': 1,\n",
              "  'word': 'agnes',\n",
              "  'start': 0,\n",
              "  'end': 5},\n",
              " {'entity': 'I-person',\n",
              "  'score': np.float32(0.98781735),\n",
              "  'index': 2,\n",
              "  'word': 'ar',\n",
              "  'start': 6,\n",
              "  'end': 8},\n",
              " {'entity': 'I-person',\n",
              "  'score': np.float32(0.83477294),\n",
              "  'index': 3,\n",
              "  'word': '##ber',\n",
              "  'start': 8,\n",
              "  'end': 11},\n",
              " {'entity': 'B-location',\n",
              "  'score': np.float32(0.7598351),\n",
              "  'index': 32,\n",
              "  'word': 'london',\n",
              "  'start': 133,\n",
              "  'end': 139},\n",
              " {'entity': 'I-creative-work',\n",
              "  'score': np.float32(0.5088698),\n",
              "  'index': 33,\n",
              "  'word': '.',\n",
              "  'start': 139,\n",
              "  'end': 140}]"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load model directly\n",
        "from transformers import AutoTokenizer, AutoModelForTokenClassification\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"ae-314/token_classification_wnut_model\")\n",
        "inputs = tokenizer(example_1, return_tensors=\"pt\") # give the model inputs\n",
        "model = AutoModelForTokenClassification.from_pretrained(\"ae-314/token_classification_wnut_model\")\n",
        "\n",
        "import torch\n",
        "\n",
        "with torch.no_grad():\n",
        "  logits = model(**inputs).logits"
      ],
      "metadata": {
        "id": "gUTThpexmowr"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# get the class predictions in human-readable labels\n",
        "\n",
        "predictions = torch.argmax(logits, dim=2)\n",
        "predicted_token_class = [model.config.id2label[t.item()] for t in predictions[0]]\n",
        "predicted_token_class"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V_DCMnVfuNdq",
        "outputId": "6ede4f93-f84b-4493-b191-78fd9beab908"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['O',\n",
              " 'B-person',\n",
              " 'I-person',\n",
              " 'I-person',\n",
              " 'O',\n",
              " 'O',\n",
              " 'O',\n",
              " 'O',\n",
              " 'O',\n",
              " 'O',\n",
              " 'O',\n",
              " 'O',\n",
              " 'O',\n",
              " 'O',\n",
              " 'O',\n",
              " 'O',\n",
              " 'O',\n",
              " 'O',\n",
              " 'O',\n",
              " 'O',\n",
              " 'O',\n",
              " 'O',\n",
              " 'O',\n",
              " 'O',\n",
              " 'O',\n",
              " 'O',\n",
              " 'O',\n",
              " 'O',\n",
              " 'O',\n",
              " 'O',\n",
              " 'O',\n",
              " 'O',\n",
              " 'B-location',\n",
              " 'I-creative-work',\n",
              " 'I-creative-work']"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "example_2 = \"Jules Richard Petri invented the Petri dish during his time at Berlin University.\"\n",
        "\n",
        "pipe(example_2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bgjqMpPQxLCO",
        "outputId": "6624f3e2-cef0-4280-e08a-3e9fdb5b77ef"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'entity': 'B-person',\n",
              "  'score': np.float32(0.9978757),\n",
              "  'index': 1,\n",
              "  'word': 'jules',\n",
              "  'start': 0,\n",
              "  'end': 5},\n",
              " {'entity': 'I-person',\n",
              "  'score': np.float32(0.9973246),\n",
              "  'index': 2,\n",
              "  'word': 'richard',\n",
              "  'start': 6,\n",
              "  'end': 13},\n",
              " {'entity': 'I-person',\n",
              "  'score': np.float32(0.99879277),\n",
              "  'index': 3,\n",
              "  'word': 'pet',\n",
              "  'start': 14,\n",
              "  'end': 17},\n",
              " {'entity': 'I-person',\n",
              "  'score': np.float32(0.9937058),\n",
              "  'index': 4,\n",
              "  'word': '##ri',\n",
              "  'start': 17,\n",
              "  'end': 19},\n",
              " {'entity': 'B-location',\n",
              "  'score': np.float32(0.97920716),\n",
              "  'index': 14,\n",
              "  'word': 'berlin',\n",
              "  'start': 63,\n",
              "  'end': 69},\n",
              " {'entity': 'I-location',\n",
              "  'score': np.float32(0.90893704),\n",
              "  'index': 15,\n",
              "  'word': 'university',\n",
              "  'start': 70,\n",
              "  'end': 80}]"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "example_3 = \"The World Wildlife Fund (WWF) was founded in 1961, is focused on conservation, and is based in Switzerland.\"\n",
        "\n",
        "pipe(example_3)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q_lSrczdx-xL",
        "outputId": "ae850f24-1a12-4007-e138-43df9948050b"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'entity': 'B-group',\n",
              "  'score': np.float32(0.60621166),\n",
              "  'index': 6,\n",
              "  'word': 'wwf',\n",
              "  'start': 25,\n",
              "  'end': 28},\n",
              " {'entity': 'B-location',\n",
              "  'score': np.float32(0.9889181),\n",
              "  'index': 22,\n",
              "  'word': 'switzerland',\n",
              "  'start': 95,\n",
              "  'end': 106}]"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "example_4 = \"The Golden State Warriors are an American professional basketball team based in San Francisco.\"\n",
        "\n",
        "pipe(example_4)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8360OEqs0EwZ",
        "outputId": "efdf6869-fbdf-4271-e3e3-cd539f26bf9a"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'entity': 'B-group',\n",
              "  'score': np.float32(0.8838734),\n",
              "  'index': 1,\n",
              "  'word': 'the',\n",
              "  'start': 0,\n",
              "  'end': 3},\n",
              " {'entity': 'B-location',\n",
              "  'score': np.float32(0.73068917),\n",
              "  'index': 2,\n",
              "  'word': 'golden',\n",
              "  'start': 4,\n",
              "  'end': 10},\n",
              " {'entity': 'I-group',\n",
              "  'score': np.float32(0.5931818),\n",
              "  'index': 3,\n",
              "  'word': 'state',\n",
              "  'start': 11,\n",
              "  'end': 16},\n",
              " {'entity': 'I-group',\n",
              "  'score': np.float32(0.9798933),\n",
              "  'index': 4,\n",
              "  'word': 'warriors',\n",
              "  'start': 17,\n",
              "  'end': 25},\n",
              " {'entity': 'B-location',\n",
              "  'score': np.float32(0.99818534),\n",
              "  'index': 13,\n",
              "  'word': 'san',\n",
              "  'start': 80,\n",
              "  'end': 83},\n",
              " {'entity': 'I-location',\n",
              "  'score': np.float32(0.99061126),\n",
              "  'index': 14,\n",
              "  'word': 'francisco',\n",
              "  'start': 84,\n",
              "  'end': 93},\n",
              " {'entity': 'I-creative-work',\n",
              "  'score': np.float32(0.85991144),\n",
              "  'index': 15,\n",
              "  'word': '.',\n",
              "  'start': 93,\n",
              "  'end': 94}]"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    }
  ]
}
